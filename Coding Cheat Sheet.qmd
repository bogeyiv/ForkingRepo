---
title: "Coding Cheat Sheet"
format: html
editor: visual
---

## Library

```{r}
library(tidyverse)
library(MASS)
library(GGally)
library(class)
```

## Equations

#### Linear Regression

```{r}
reg <- lm(Y ~ X, data = DATA)
summary(reg)
broom::tidy(reg, conf.int = TRUE)
```

#### Prediction MSE

```{r}
# 1. Set the seed (if required).
set.seed(1234)

# 2a. Create the Z with a training percentage.
training_pct <- 0.5
Z = sample(nrow(DATA), training_pct*nrow(DATA))

#2b. Create a Z with a number of observations
Z <- sample(nrow(DATA), NUM)
training <- DATA[Z,]
test <- DATA[-Z,]

# 3. Calculate the regression with training subset (Z).
reg <- lm(Y ~ X, subset = Z, data - DATA)

# 4. Use testing data to generate predictions.
Y <- DATA$SUB[-Z]
Yhat <- predict(reg, newdata = DATA[-Z,])

# 5a. Calculate Prediction MSE.
MSE <- mean((Yhat - Y)^2)
MSE

#5b. Calculate Root Mean Squared Error
RMSE <- sqrt(mean((Yhat - Y)^2))
```

#### F Test (One Variable, Multiple Variables)

```{r}
# 1. Create the full model (all predictors).
full <- lm(Y ~ X1 + X2, data = DATA)

# 2. Create the reduced model (remove irrelevant predictors).
reduced <- lm(Y ~ X, data = DATA)

# 3. Conduct ANOVA.
an_out <- anova(reduced, full)
an_out
```

#### F Test (Lack of Fit and Saturated Lack of Fit)

```{r}
# 1a. Create reduced model (linear model).
lm_red <- lm(Y ~ X1 + X2, data = DATA)

# 1b. Create a full model (non-linear model).
DATA <- mutate(X1_CAT = as.factor(X1),
               X2_CAT = as.factor(X2))
lm_full <- lm(Y ~ X1 * X2, data = DATA)

# 1c. Conduct ANOVA.
anova(lm_red, lm_full)

# 2a. Create reduced model (linear model).
lm_red <- lm(Y ~ X1 + X2 + X3, data = DATA)

# 2b. Create a full model (saturated with quadratics or interaction effects).  Mutate variables with quadratics if required.
lm_full <- lm(Y ~ X1 * X2 + (X3)^2, data = DATA)

# 2c. Conduct ANOVA.
anova(lm_red, lm_full)

# Additional Tools:
# Confirm repeated values of X.
nrow(DATA) - length(unique(DATA$X))
nrow(DATA) - length(as.factor(DATA$X))
broom::glance(lm_full)$df.residual

# Create repeated values of X
X <-  round(DATA$X/100) * 100
head(X)
length(unique(X))
reg_r <- lm(DATA$X ~ (X))
anova(reg_r, lm_full)
```

#### Categorical Variables and Interaction Terms

```{r}
# 1a. Test the significance of the overall predictor.
full <- lm(Y ~ X1 + CATX2, data = DATA)
summary(full)

# 1b. Convert the categorical variable with "as.factor".
full <- lm(Y ~ X + as.factor(CATX2), data = DATA)
summary(full)

#2a. Create interaction effect (shorthand for A + B + A:B).
reg <- lm(Y ~ X1 * X2, data = DATA)

# You can use ANOVA to compare reduced (no interaction) and full (interaction effects) models.
```

#### KNN

```{r}
# 1. Set seed, training percentage, and create variables.
set.seed(1234)
training_pct <- .70
Z = sample(nrow(DATA), floor(training_pct*nrow(DATA)))
Xtrain = DATA[Z,] # Use c("X") to include predictors.
Ytrain = DATA$Y[Z]
Xtest = DATA[-Z,] # Use c("X") to include predictors.
Yhat <- knn(Xtrain, Xtest, Ytrain, k = 9)
Ytest <- DATA$Y[-Z]

# 2. Compute confusion matrix.
conf_matrix <- table(Ytest, Yhat)
conf_matrix

# 3. Compute classification rate (overall fraction of correct predictions).
class_rate = (table(Ytest, Yhat)[1, 1] + table(Ytest, Yhat)[2, 2])/((1 - training_pct)*nrow(DATA))
class_rate

# 4. Tuning to determine optimal K and minimizes prediction error rate.

# 4a. Initialize data
err_class <- rep(1:100)
tpr <- rep(1:100)
fpr <- rep(1:100)

# 4b. Run the loop.
for (k in 1:100){
  Yhat <- knn(Xtrain, Xtest, Ytrain, k = k) 
  err_class[k] <- mean(Yhat != Ytest) # The prediction is not correct.
  tpr[k] <- sum(Yhat == 1 & Ytest == 1) / sum(Ytest == 1) # TP/P.
  fpr[k] <- sum(Yhat == 1 & Ytest == 0) / sum(Ytest == 0) # FP/N.
}
ggplot(tibble(err_class, k = 1:100), aes(x = k, y = err_class)) +
  geom_line()

# 4c. Determine optimal K.
which.min(err_class)

# 4d. Determine probability of a mis-classification.
err_class[which.min(err_class)]
```

#### Logistic Regression

```{r}
# 1. Remove N/As
DATA <- tidyr::drop_na(DATA, c(X1, X2))

# 2. Split between training and testing data.
set.seed(1234)
training_pct <- .6
Z <- sample(nrow(DATA), floor(training_pct*nrow(DATA)))
train <- DATA[Z,]
test <- DATA[-Z,]

# 3. Run the model on the training data.
logreg <- glm(as.factor(Y) ~ X1 + X2, data = train, family = "binomial")

# 4. Get predictions on the test data.
Prob <- predict(logreg, type = "response", newdata = test)

# 5. Set up the possible thresholds.
threshold <- seq(0, 1, .01)
TPR <-  FPR <- err.rate <- rep(0, length(threshold))

# 6. Test all possible thresholds.
for (i in seq_along(threshold)) {
Yhat <- rep(NA_character_, nrow(test)) 
Yhat <-  ifelse(Prob >= threshold[[i]], "yes", "no")

err.rate[i] <- mean(Yhat != test$Y)
TPR[[i]] <- sum(Yhat == "yes" & test$Y == "yes")/
  sum(test$Y == "yes")
FPR[[i]] <- sum(Yhat == "yes" & test$Y == "no")/
  sum(test$Y == "no")
}

# 7. Graph outcomes.
ggplot(tibble(threshold, err.rate), aes(threshold, err.rate)) + 
  geom_point()

# 8. Determine threshold and optimal prediction error classification rate for the test data.
which.min(err.rate)
threshold[which.min(err.rate)]
min(err.rate)

# For predictions:
predict(logreg, type = "response", 
            data.frame(X1 = "value", X2 = 10))
```

#### Confusion Matrix

```{r}
# If threshold is known, use the code below:
# 1a. Create logistic regression model.
glmout <- glm(Y ~ X1 + X2, family = "binomial", data = DATA)
summary(glmout)

# 1b. 
Probability = predict(glmout, type ="response")
Predicted.Direction = rep("NEG",length(Probability))
Predicted.Direction[Probability > 0.5] = "POS"
Predicted.Direction <- ifelse(Probability >= .5, "POS", "NEG")
table(DATA$Y, Predicted.Direction)

# OR

train = Weekly[Weekly$Year <= 2007,] # Example for training.
test = Weekly[Weekly$Year > 2007,] # Example for testing.
glmoutr = glm(Y ~ X1 + X2, family="binomial", data = train)
summary(glmoutr)
Probability = predict(glmoutr, data.frame(test), type ="response")
Predicted.Direction <-  ifelse(Probability >= .5, "POS", "NEG")
table(test$Y, Predicted.Direction)

# If the threshold is unknown (finding optimal threshold), use code below:
# 2a. Set seed, create variables, run logistic regression model.
set.seed(1234)
training_pct <- .5
Z <- sample(nrow(DATA), floor(training_pct*nrow(DATA)))
logreg <- glm(as.factor(Y) ~ X1 + X2, 
              data = DATA[Z,], family = "binomial")
summary(logreg)
Prob <- predict(logreg, type = "response")
threshold <- seq(0, 1, .01)

# 2b. Run for loop.
TPR <-  FPR <- err.rate <- rep(0, length(threshold))

for (i in seq_along(threshold)) {
Yhat <- rep(NA_character_, nrow(DATA[Z,])) 
Yhat <-  ifelse(Prob >= threshold[[i]], "yes", "no")

err.rate[i] <- mean(Yhat != DATA[Z,]$survived)
TPR[[i]] <- sum(Yhat == "yes" & DATA[Z,]$survived == "yes") /
  sum(DATA[Z,]$survived == "yes")
FPR[[i]] <- sum(Yhat == "yes" & DATA[Z,]$survived == "no") /
  sum(DATA[Z,]$survived == "no")
}
ggplot(tibble(threshold, err.rate),
       aes(threshold, err.rate)) + 
  geom_point()

# 2c. Determine general threshold and optimized threshold.
mean(DATA[Z,]$survived == "yes") # General threshold (how many hits in our training data).
which.min(err.rate) # Threshold value for R.
threshold[52] # Actual threshold value.
min(err.rate) # Minimial error rate.

# 2d. Create confusion matrix.
Yhat <- ifelse(Prob >= threshold[which.min(err.rate)], "yes", "no")
table(Yhat, DATA[Z,]$Y)
```

#### LDA

```{r}
train = Weekly[Weekly$Year <= 2007,] # Example for training.
test = Weekly[Weekly$Year > 2007,] # Example for testing.
lda <- lda(Y ~ X, data = train) # Don't need CV = TRUE.
Predicted.Direction_lda  <-  predict(lda, data.frame(test))$class
table(test$Y, Predicted.Direction_lda)
round(100*sum(lda$class != lda$true_q) / nrow(DATA), 2) # LDA Error Rate.
```

#### QDA

```{r}
train = Weekly[Weekly$Year <= 2007,] # Example for training.
test = Weekly[Weekly$Year > 2007,] # Example for testing.
qda <- qda(Y ~ X, data = train) # Don't need CV = TRUE.
Predicted.Direction_qda  <-  predict(qda, data.frame(test))$class
table(test$Y, Predicted.Direction_qda)
round(100 * sum(qda$class != qda$true_q) / nrow(DATA), 2) #QDA Error Rate.
```

## Plots

#### Pairs Plot

```{r}
ggpairs(DATA)
```

#### Residual, Q-Q, Standardized Residuals, and Cooks Distance Plots

```{r}
plot(reg)
```

#### Added Variable Plots

```{r}
car::av.plot(reg)
```

#### Model Error Rate

```{r}
# Note: if you are comparing two models, change the name of the "err.rate" in each loop.
ggplot() + 
  geom_point(tibble(threshold, err.rate1),
             mapping = aes(threshold, err.rate1), color = "red", size = .1) +
  geom_line(data = tibble(threshold, err.rate2),
             mapping = aes(threshold, err.rate2), color = "blue", linewidth = .2) +
ggtitle("Full Model Error Rate (Blue) and Reduced Model Rrror Rate (Red)")
```

#### ROC Curve

```{r}
ggplot(tibble(TPR,FPR),
       aes(FPR, TPR)) + 
  geom_point() +
  geom_abline(color = "red", lty = 2)

# Note: if you are comparing two models, change the name of the TPR and FPR in the loop.
df <- tibble(TPR_A = c(TPR1, TPR2), FPR_A = c(FPR1, FPR2)) |> 
  mutate(curve = c(rep("Reduced", length(TPR1)), 
                       rep("Full", length(TPR2)))
  )

ggplot(df, aes(FPR_A, TPR_A, color = curve)) +
  geom_line(linewidth= .2)
```
